{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\romaa\\\\project2019', 'C:\\\\Users\\\\romaa\\\\Anaconda3', 'C:\\\\Users\\\\romaa\\\\Anaconda3\\\\python37.zip', 'C:\\\\Users\\\\romaa\\\\Anaconda3\\\\DLLs', 'C:\\\\Users\\\\romaa\\\\Anaconda3\\\\lib', '', 'C:\\\\Users\\\\romaa\\\\Anaconda3\\\\lib\\\\site-packages', 'C:\\\\Users\\\\romaa\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\romaa\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\romaa\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\romaa\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\romaa\\\\.ipython']\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9313013b1274>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcsv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "from csv import reader\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model as lm\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "\n",
    "rental = np.array([221, 342, 568, 216, 316, 210, 340, 326, 106, 259,\n",
    "                   302, 639, 540, 341, 212, 222, 336, 116, 124, 385,\n",
    "                   247, 162, 329, 118, 128, 346, 907, 144, 529, 501\n",
    "                  ])\n",
    "features = ['년',\n",
    "           '월', \n",
    "           '시', \n",
    "           '기온(°C)',\n",
    "           '강수량(mm)', \n",
    "           '풍속(m/s)', \n",
    "           '습도(%)', \n",
    "           '적설(cm)',\n",
    "           '미세먼지',\n",
    "           '초미세먼지',\n",
    "           '요일_0', \n",
    "           '요일_1', \n",
    "           '요일_2', \n",
    "           '요일_3',\n",
    "           '요일_4', \n",
    "           '요일_5', \n",
    "           '요일_6']\n",
    "\n",
    "try:\n",
    "    t = pd.read_pickle('data/pickle/미세먼지_30수요.pkl')\n",
    "    \n",
    "except:\n",
    "    \n",
    "    df1 = pd.DataFrame(pd.read_csv(\"data/database/201801.csv\"))\n",
    "    df2 = pd.DataFrame(pd.read_csv(\"data/database/201802.csv\"))\n",
    "    df3 = pd.DataFrame(pd.read_csv(\"data/database/201803.csv\"))\n",
    "    df4 = pd.DataFrame(pd.read_csv(\"data/database/201804.csv\"))\n",
    "    df5 = pd.DataFrame(pd.read_csv(\"data/database/201805.csv\"))\n",
    "    df6_1 = pd.DataFrame(pd.read_csv(\"data/database/201806_01.csv\"))\n",
    "    df6_2 = pd.DataFrame(pd.read_csv(\"data/database/201806_02.csv\"))\n",
    "    df6 = pd.concat([df6_1, df6_2])\n",
    "    df7_1 = pd.DataFrame(pd.read_csv(\"data/database/201807_01.csv\"))\n",
    "    df7_2 = pd.DataFrame(pd.read_csv(\"data/database/201807_02.csv\"))\n",
    "    df7 = pd.concat([df7_1, df7_2])\n",
    "    df8 = pd.DataFrame(pd.read_csv(\"data/database/201808.csv\"))\n",
    "    df9_1 = pd.DataFrame(pd.read_csv(\"data/database/201809_1.csv\"))\n",
    "    df9_2 = pd.DataFrame(pd.read_csv(\"data/database/201809_2.csv\"))\n",
    "    df9 = pd.concat([df9_1, df9_2])\n",
    "    df10_1 = pd.DataFrame(pd.read_csv(\"data/database/201810_01.csv\"))\n",
    "    df10_2 = pd.DataFrame(pd.read_csv(\"data/database/201810_02.csv\"))\n",
    "    df10 = pd.concat([df10_1, df10_2])\n",
    "    df11 = pd.DataFrame(pd.read_csv(\"data/database/201811.csv\"))\n",
    "    df12 = pd.DataFrame(pd.read_csv(\"data/database/201812.csv\"))\n",
    "\n",
    "\n",
    "    df2017_1 = pd.DataFrame(pd.read_csv(\"data/database/201701.csv\"))\n",
    "    df2017_2 = pd.DataFrame(pd.read_csv(\"data/database/201702.csv\"))\n",
    "    df2017_3 = pd.DataFrame(pd.read_csv(\"data/database/201703.csv\"))\n",
    "    df2017_4 = pd.DataFrame(pd.read_csv(\"data/database/201704.csv\"))\n",
    "    df2017_5 = pd.DataFrame(pd.read_csv(\"data/database/201705.csv\"))\n",
    "    df2017_6 = pd.DataFrame(pd.read_csv(\"data/database/201706.csv\"))\n",
    "    df2017_7 = pd.DataFrame(pd.read_csv(\"data/database/201707.csv\"))\n",
    "    df2017_8 = pd.DataFrame(pd.read_csv(\"data/database/201708.csv\"))\n",
    "    df2017_9 = pd.DataFrame(pd.read_csv(\"data/database/201709.csv\"))\n",
    "    df2017_10 = pd.DataFrame(pd.read_csv(\"data/database/201710.csv\"))\n",
    "    df2017_11 = pd.DataFrame(pd.read_csv(\"data/database/201711.csv\"))\n",
    "    df2017_12 = pd.DataFrame(pd.read_csv(\"data/database/201712.csv\"))\n",
    "\n",
    "    df = [[df2017_1, df2017_2, df2017_3, df2017_4, df2017_5, df2017_6, df2017_7, df2017_8, df2017_9, df2017_10, df2017_11, df2017_12],[df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12]]\n",
    "    \n",
    "    def load_2019_df(rental_no, w , df2019_1, df2019_2, df2019_3):\n",
    "        wt = load_weather_month(w, 1)\n",
    "        datat, baset = calculate_date(df2019_1)\n",
    "        temp = concat_columns(datat, wt, baset, rental_no)\n",
    "\n",
    "        wt1 = load_weather_month(w, 2)\n",
    "        datat1, baset1 = calculate_date(df2019_2)\n",
    "        temp1 = concat_columns(datat1, wt1, baset1, rental_no)\n",
    "\n",
    "        wt3 = load_weather_month(w, 3)\n",
    "        datat2, baset2 = calculate_date(df2019_3)\n",
    "        temp2 = concat_columns(datat2, wt3, baset2, rental_no)\n",
    "    \n",
    "        result = pd.concat([temp, temp1, temp2])\n",
    "        return result\n",
    "        \n",
    "    def load_2019():\n",
    "        df2019_1 = pd.DataFrame(pd.read_csv(\"data/database/201901.csv\"))\n",
    "        df2019_2 = pd.DataFrame(pd.read_csv(\"data/database/201902.csv\"))\n",
    "        df2019_3 = pd.DataFrame(pd.read_csv(\"data/database/201903.csv\"))\n",
    "        weather = pd.read_csv(\"data/database/2019weather.csv\")\n",
    "        dfw1 = pd.DataFrame(weather)\n",
    "        dfw1['일시'] = pd.to_datetime(dfw1['일시'], errors='coerce')\n",
    "        dfw1['월'] = dfw1['일시'].dt.month\n",
    "        dfw1['일'] = dfw1['일시'].dt.day\n",
    "        dfw1['시'] = dfw1['일시'].dt.hour\n",
    "        \n",
    "        tt = pd.DataFrame()\n",
    "        \n",
    "        for i in range(len(rental)):\n",
    "            tt = pd.concat([tt, load_2019_df(rental[i], dfw1, df2019_1, df2019_2, df2019_3)]).reset_index(drop=True)\n",
    "        \n",
    "        return tt  \n",
    "    \n",
    "    def load_weather():\n",
    "        weather = pd.read_csv(\"data/database/2017weather.csv\")\n",
    "        dfw1 = pd.DataFrame(weather)\n",
    "        dfw1['일시'] = pd.to_datetime(dfw1['일시'], errors='coerce')\n",
    "        dfw1['월'] = dfw1['일시'].dt.month\n",
    "        dfw1['일'] = dfw1['일시'].dt.day\n",
    "        dfw1['시'] = dfw1['일시'].dt.hour\n",
    "        weather1 = pd.read_csv(\"data/database/2018weather.csv\")\n",
    "        dfw2 = pd.DataFrame(weather1)\n",
    "        dfw2['일시'] = pd.to_datetime(dfw2['일시'], errors='coerce')\n",
    "        dfw2['월'] = dfw2['일시'].dt.month\n",
    "        dfw2['일'] = dfw2['일시'].dt.day\n",
    "        dfw2['시'] = dfw2['일시'].dt.hour\n",
    "        dfw = [dfw1, dfw2]\n",
    "        return dfw\n",
    "\n",
    "    dfw = load_weather()\n",
    "\n",
    "    def load_weather_month(weather, mon):\n",
    "        weather1 = weather[weather['월'] == mon]\n",
    "        weather1 = weather1.drop(['일시','월'], 1).reset_index(drop=True)\n",
    "        return weather1\n",
    "\n",
    "    def calculate_date(df):\n",
    "        dft = df\n",
    "        dft['대여시간'] = pd.to_datetime(dft['대여시간'], errors='coerce')\n",
    "        dft['년'] = dft['대여시간'].dt.year - 2010\n",
    "        dft['요일'] = dft['대여시간'].dt.weekday\n",
    "        dft['월'] = dft['대여시간'].dt.month\n",
    "        dft['일'] = dft['대여시간'].dt.day\n",
    "        dft['시'] = dft['대여시간'].dt.hour\n",
    "        base = pd.DataFrame(dft.drop_duplicates(['일','시'])).reset_index(drop=True)\n",
    "\n",
    "        dftemp = df[df['대여장소'].isin(rental)]\n",
    "        return dftemp, base\n",
    "\n",
    "    def concat_columns(dftemp, dfw, base, rental_no):\n",
    "        temp1 = base\n",
    "        dftemp113 = dftemp[dftemp['대여장소'] == rental_no]\n",
    "        #print(pd.crosstab(dftemp113['일'], dftemp113['시'], margins=False))\n",
    "        fre = pd.crosstab(dftemp113['일'], dftemp113['시'], margins=False).values.flatten()\n",
    "        frelist = fre.tolist()\n",
    "\n",
    "        for i in range(int(dfw.shape[0]/24)):\n",
    "            if((dftemp113[dftemp113['일'] == (i+1)]).shape[0]==0):\n",
    "                for x in range(24):\n",
    "                    frelist.insert((i*24)+x ,0)\n",
    "\n",
    "        for i in range(24):\n",
    "            if((dftemp113[dftemp113['시'] == i]).shape[0]==0):\n",
    "                for x in range(int(dfw.shape[0]/24)):\n",
    "                    frelist.insert((i+(x*24)),0)\n",
    "    \n",
    "        fre = np.array(frelist)                        \n",
    "        fre = pd.DataFrame(fre, columns=['건수'])\n",
    "    #print(fre.shape)\n",
    "        temp1['대여장소'] = rental_no\n",
    "        temp1['빈도수'] = fre['건수']\n",
    "        temp1 = temp1.drop(['반납장소', '대여시간', '반납시간'], 1)\n",
    "        temp1 = pd.merge(temp1, dfw, on=['일', '시'])\n",
    "        temp1 = temp1.drop(['일'], 1)\n",
    "        return temp1\n",
    "\n",
    "    def data_no(rental_no):\n",
    "        dfwlist = []\n",
    "        data = [0 for _ in range(12)]\n",
    "        base = [0 for _ in range(12)]\n",
    "        temp = [0 for _ in range(12)]\n",
    "        r = pd.DataFrame()\n",
    "        for x in range(len(dfw)):\n",
    "            for i in range(12):\n",
    "                dfwlist.append(load_weather_month(dfw[x], i+1))\n",
    "\n",
    "            for i in range(12):\n",
    "                data[i], base[i] = calculate_date(df[x][i])\n",
    "\n",
    "            for i in range(12):\n",
    "                temp[i] = concat_columns(data[i], dfwlist[12*x+i], base[i], rental_no)\n",
    "\n",
    "            result = pd.concat([temp[0],temp[1],temp[2],temp[3],temp[4],temp[5],temp[6],temp[7],temp[8],temp[9],temp[10],temp[11]]).reset_index(drop=True)\n",
    "            r = pd.concat([r, result])\n",
    "\n",
    "        return r.reset_index(drop=True)\n",
    "    \n",
    "    t2019 = load_2019()\n",
    "    \n",
    "    t2018 = pd.DataFrame()\n",
    "    for i in range(len(rental)):\n",
    "        t2018= pd.concat([t2018, data_no(rental[i])]).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    t2018 = t2018.join(pd.get_dummies(t2018['요일'], prefix=\"요일\"))\n",
    "    t2019 = t2019.join(pd.get_dummies(t2019['요일'], prefix=\"요일\"))\n",
    "    \n",
    "    t = pd.concat([t2018,t2019]).reset_index(drop=True)    \n",
    "    t.to_pickle('data/pickle/미세먼지_30수요.pkl')\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "n = 3\n",
    "results = {} \n",
    "total = t['대여장소'].nunique()  # 서로다른 대기소 갯수 30개\n",
    "# print(total)  # 10\n",
    "for idx, (name, _df) in enumerate(t.groupby('대여장소'), 1):\n",
    "    print()\n",
    "    print(\"[%d/%d] %d번 대여소\" %(idx, total, name), end=' ')  #name은 대여소 코드.\n",
    "    print()\n",
    "      \n",
    "    x_train, x_test, y_train, y_test = train_test_split(_df[features], _df['빈도수'], test_size=0.05, random_state=15) \n",
    "    \n",
    "    param_grid = { \n",
    "        \"gamma\": uniform(0, 0.5).rvs(n), \n",
    "        \"max_depth\": range(2, 7), # default 3 \n",
    "        \"n_estimators\": randint(100, 150).rvs(n), # default 100 \n",
    "    } \n",
    "        \n",
    "        \n",
    "    grid = GridSearchCV(xgb.XGBRegressor(objective='reg:squarederror'), cv=5, n_jobs=-1, param_grid=param_grid, verbose=1) \n",
    "        \n",
    "    grid = grid.fit(x_train, y_train) \n",
    "        \n",
    "        \n",
    "    model = grid.best_estimator_\n",
    "    predictions = model.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "        \n",
    "    model.save_model(\"data/model/수요\" + str(int(name)) + \".model\")\n",
    "        \n",
    "    for i in range(0, 5):\n",
    "        print('>predicted=' +str(predictions[i]) + ', actual=' + str(y_test.values[i]))\n",
    "    print(x_test)\n",
    "            \n",
    "    results[name] = {}\n",
    "    results[name]['model'] = model  #best_estimator 저장\n",
    "    results[name]['mae'] = mae\n",
    "    print(mae)\n",
    "    results[name]['errors'] = predictions - y_test  \n",
    "\n",
    "\n",
    "errors = np.array([result['mae'] for result in results.values()])\n",
    "errors.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
