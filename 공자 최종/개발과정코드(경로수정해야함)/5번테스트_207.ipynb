{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       대여장소  년  요일  월   시  빈도수  기온(°C)  강수량(mm)  풍속(m/s)  습도(%)  적설(cm)  요일_0  \\\n",
      "0       207  7   6  1   0    0     0.2      0.0      2.2     79     0.0     0   \n",
      "1       207  7   6  1   1    0     0.0      0.0      1.4     78     0.0     0   \n",
      "2       207  7   6  1   2    0    -0.3      0.0      1.9     81     0.0     0   \n",
      "3       207  7   6  1   3    0    -0.7      0.0      2.0     84     0.0     0   \n",
      "4       207  7   6  1   4    0    -1.1      0.0      1.6     85     0.0     0   \n",
      "5       207  7   6  1   5    0    -1.4      0.0      1.4     86     0.0     0   \n",
      "6       207  7   6  1   6    0    -1.5      0.0      1.6     87     0.0     0   \n",
      "7       207  7   6  1   7    0    -1.5      0.0      1.4     87     0.0     0   \n",
      "8       207  7   6  1   8    0    -1.3      0.0      1.4     87     0.0     0   \n",
      "9       207  7   6  1   9    0    -0.4      0.0      1.6     83     0.0     0   \n",
      "10      207  7   6  1  10    0     0.8      0.0      2.1     77     0.0     0   \n",
      "11      207  7   6  1  11    1     2.5      0.0      1.9     71     0.0     0   \n",
      "12      207  7   6  1  12    2     4.0      0.0      1.3     69     0.0     0   \n",
      "13      207  7   6  1  13    0     5.1      0.0      1.4     65     0.0     0   \n",
      "14      207  7   6  1  14    2     6.7      0.0      0.7     61     0.0     0   \n",
      "15      207  7   6  1  15    0     6.9      0.0      0.9     65     0.0     0   \n",
      "16      207  7   6  1  16    3     6.8      0.0      1.2     67     0.0     0   \n",
      "17      207  7   6  1  17    4     6.5      0.0      0.7     69     0.0     0   \n",
      "18      207  7   6  1  18    0     5.6      0.0      2.4     70     0.0     0   \n",
      "19      207  7   6  1  19    0     4.8      0.0      2.2     73     0.0     0   \n",
      "20      207  7   6  1  20    0     4.2      0.0      1.9     73     0.0     0   \n",
      "21      207  7   6  1  21    2     4.0      0.0      2.6     74     0.0     0   \n",
      "22      207  7   6  1  22    0     3.9      0.0      1.4     75     0.0     0   \n",
      "23      207  7   6  1  23    2     3.9      0.0      1.4     75     0.0     0   \n",
      "24      207  7   0  1   0    0     3.9      0.0      1.5     75     0.0     1   \n",
      "25      207  7   0  1   1    0     3.9      0.0      2.1     75     0.0     1   \n",
      "26      207  7   0  1   2    0     3.8      0.0      2.2     77     0.0     1   \n",
      "27      207  7   0  1   3    0     3.7      0.0      1.7     76     0.0     1   \n",
      "28      207  7   0  1   4    0     3.7      0.0      1.5     77     0.0     1   \n",
      "29      207  7   0  1   5    0     3.7      0.0      1.5     80     0.0     1   \n",
      "...     ... ..  .. ..  ..  ...     ...      ...      ...    ...     ...   ...   \n",
      "19650   207  9   5  3  18    1     4.7      0.0      4.2     66     0.0     0   \n",
      "19651   207  9   5  3  19    1     3.7      0.0      4.9     65     0.0     0   \n",
      "19652   207  9   5  3  20    0     3.6      0.0      4.3     68     0.0     0   \n",
      "19653   207  9   5  3  21    1     3.7      0.1      3.7     69     0.0     0   \n",
      "19654   207  9   5  3  22    0     3.9      0.0      3.5     69     0.0     0   \n",
      "19655   207  9   5  3  23    2     4.1      0.0      4.2     70     0.0     0   \n",
      "19656   207  9   6  3   0    2     3.7      0.0      3.8     72     0.0     0   \n",
      "19657   207  9   6  3   1    0     3.4      0.0      4.4     69     0.0     0   \n",
      "19658   207  9   6  3   2    0     3.2      0.0      4.8     70     0.0     0   \n",
      "19659   207  9   6  3   3    0     3.3      0.0      3.4     69     0.0     0   \n",
      "19660   207  9   6  3   4    0     3.2      0.0      3.1     69     0.0     0   \n",
      "19661   207  9   6  3   5    0     3.2      0.0      2.9     70     0.0     0   \n",
      "19662   207  9   6  3   6    1     3.1      0.0      3.0     69     0.0     0   \n",
      "19663   207  9   6  3   7    0     3.0      0.0      1.5     67     0.0     0   \n",
      "19664   207  9   6  3   8    1     3.0      0.0      2.8     63     0.0     0   \n",
      "19665   207  9   6  3   9    4     3.1      0.0      2.6     60     0.0     0   \n",
      "19666   207  9   6  3  10    7     3.5      0.0      3.7     58     0.0     0   \n",
      "19667   207  9   6  3  11    1     4.2      0.0      2.7     53     0.0     0   \n",
      "19668   207  9   6  3  12    4     5.0      0.0      4.1     47     0.0     0   \n",
      "19669   207  9   6  3  13    9     4.8      0.0      3.1     51     0.0     0   \n",
      "19670   207  9   6  3  14    9     5.3      0.0      2.9     46     0.0     0   \n",
      "19671   207  9   6  3  15   12     6.7      0.0      3.0     35     0.0     0   \n",
      "19672   207  9   6  3  16   18     8.0      0.0      3.3     24     0.0     0   \n",
      "19673   207  9   6  3  17   29     7.5      0.0      4.4     20     0.0     0   \n",
      "19674   207  9   6  3  18    9     6.8      0.0      3.2     27     0.0     0   \n",
      "19675   207  9   6  3  19    6     5.9      0.0      3.1     24     0.0     0   \n",
      "19676   207  9   6  3  20    6     4.9      0.0      2.6     24     0.0     0   \n",
      "19677   207  9   6  3  21    2     4.2      0.0      3.1     25     0.0     0   \n",
      "19678   207  9   6  3  22    0     3.6      0.0      2.8     28     0.0     0   \n",
      "19679   207  9   6  3  23    4     3.0      0.0      1.6     31     0.0     0   \n",
      "\n",
      "       요일_1  요일_2  요일_3  요일_4  요일_5  요일_6  \n",
      "0         0     0     0     0     0     1  \n",
      "1         0     0     0     0     0     1  \n",
      "2         0     0     0     0     0     1  \n",
      "3         0     0     0     0     0     1  \n",
      "4         0     0     0     0     0     1  \n",
      "5         0     0     0     0     0     1  \n",
      "6         0     0     0     0     0     1  \n",
      "7         0     0     0     0     0     1  \n",
      "8         0     0     0     0     0     1  \n",
      "9         0     0     0     0     0     1  \n",
      "10        0     0     0     0     0     1  \n",
      "11        0     0     0     0     0     1  \n",
      "12        0     0     0     0     0     1  \n",
      "13        0     0     0     0     0     1  \n",
      "14        0     0     0     0     0     1  \n",
      "15        0     0     0     0     0     1  \n",
      "16        0     0     0     0     0     1  \n",
      "17        0     0     0     0     0     1  \n",
      "18        0     0     0     0     0     1  \n",
      "19        0     0     0     0     0     1  \n",
      "20        0     0     0     0     0     1  \n",
      "21        0     0     0     0     0     1  \n",
      "22        0     0     0     0     0     1  \n",
      "23        0     0     0     0     0     1  \n",
      "24        0     0     0     0     0     0  \n",
      "25        0     0     0     0     0     0  \n",
      "26        0     0     0     0     0     0  \n",
      "27        0     0     0     0     0     0  \n",
      "28        0     0     0     0     0     0  \n",
      "29        0     0     0     0     0     0  \n",
      "...     ...   ...   ...   ...   ...   ...  \n",
      "19650     0     0     0     0     1     0  \n",
      "19651     0     0     0     0     1     0  \n",
      "19652     0     0     0     0     1     0  \n",
      "19653     0     0     0     0     1     0  \n",
      "19654     0     0     0     0     1     0  \n",
      "19655     0     0     0     0     1     0  \n",
      "19656     0     0     0     0     0     1  \n",
      "19657     0     0     0     0     0     1  \n",
      "19658     0     0     0     0     0     1  \n",
      "19659     0     0     0     0     0     1  \n",
      "19660     0     0     0     0     0     1  \n",
      "19661     0     0     0     0     0     1  \n",
      "19662     0     0     0     0     0     1  \n",
      "19663     0     0     0     0     0     1  \n",
      "19664     0     0     0     0     0     1  \n",
      "19665     0     0     0     0     0     1  \n",
      "19666     0     0     0     0     0     1  \n",
      "19667     0     0     0     0     0     1  \n",
      "19668     0     0     0     0     0     1  \n",
      "19669     0     0     0     0     0     1  \n",
      "19670     0     0     0     0     0     1  \n",
      "19671     0     0     0     0     0     1  \n",
      "19672     0     0     0     0     0     1  \n",
      "19673     0     0     0     0     0     1  \n",
      "19674     0     0     0     0     0     1  \n",
      "19675     0     0     0     0     0     1  \n",
      "19676     0     0     0     0     0     1  \n",
      "19677     0     0     0     0     0     1  \n",
      "19678     0     0     0     0     0     1  \n",
      "19679     0     0     0     0     0     1  \n",
      "\n",
      "[19680 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model as lm\n",
    "from scipy.stats import uniform, randint\n",
    "import xgboost as xgb\n",
    "\n",
    "rental = np.array([207, 502, 113, 2102, 1210, 152, 1308, 2219, 1906, 907])\n",
    "features = ['년',\n",
    "           '월', \n",
    "           '시', \n",
    "           '기온(°C)',\n",
    "           '강수량(mm)', \n",
    "           '풍속(m/s)', \n",
    "           '습도(%)', \n",
    "           '적설(cm)',\n",
    "           '요일_0', \n",
    "           '요일_1', \n",
    "           '요일_2', \n",
    "           '요일_3',\n",
    "           '요일_4', \n",
    "           '요일_5', \n",
    "           '요일_6']\n",
    "\n",
    "try:\n",
    "    t = pd.read_pickle('data/pickle/5번테스트.pkl')\n",
    "    \n",
    "except:\n",
    "    \n",
    "    df1 = pd.DataFrame(pd.read_csv(\"data/database/201801.csv\"))\n",
    "    df2 = pd.DataFrame(pd.read_csv(\"data/database/201802.csv\"))\n",
    "    df3 = pd.DataFrame(pd.read_csv(\"data/database/201803.csv\"))\n",
    "    df4 = pd.DataFrame(pd.read_csv(\"data/database/201804.csv\"))\n",
    "    df5 = pd.DataFrame(pd.read_csv(\"data/database/201805.csv\"))\n",
    "    df6_1 = pd.DataFrame(pd.read_csv(\"data/database/201806_01.csv\"))\n",
    "    df6_2 = pd.DataFrame(pd.read_csv(\"data/database/201806_02.csv\"))\n",
    "    df6 = pd.concat([df6_1, df6_2])\n",
    "    df7_1 = pd.DataFrame(pd.read_csv(\"data/database/201807_01.csv\"))\n",
    "    df7_2 = pd.DataFrame(pd.read_csv(\"data/database/201807_02.csv\"))\n",
    "    df7 = pd.concat([df7_1, df7_2])\n",
    "    df8 = pd.DataFrame(pd.read_csv(\"data/database/201808.csv\"))\n",
    "    df9_1 = pd.DataFrame(pd.read_csv(\"data/database/201809_1.csv\"))\n",
    "    df9_2 = pd.DataFrame(pd.read_csv(\"data/database/201809_2.csv\"))\n",
    "    df9 = pd.concat([df9_1, df9_2])\n",
    "    df10_1 = pd.DataFrame(pd.read_csv(\"data/database/201810_01.csv\"))\n",
    "    df10_2 = pd.DataFrame(pd.read_csv(\"data/database/201810_02.csv\"))\n",
    "    df10 = pd.concat([df10_1, df10_2])\n",
    "    df11 = pd.DataFrame(pd.read_csv(\"data/database/201811.csv\"))\n",
    "    df12 = pd.DataFrame(pd.read_csv(\"data/database/201812.csv\"))\n",
    "\n",
    "\n",
    "    df2017_1 = pd.DataFrame(pd.read_csv(\"data/database/201701.csv\"))\n",
    "    df2017_2 = pd.DataFrame(pd.read_csv(\"data/database/201702.csv\"))\n",
    "    df2017_3 = pd.DataFrame(pd.read_csv(\"data/database/201703.csv\"))\n",
    "    df2017_4 = pd.DataFrame(pd.read_csv(\"data/database/201704.csv\"))\n",
    "    df2017_5 = pd.DataFrame(pd.read_csv(\"data/database/201705.csv\"))\n",
    "    df2017_6 = pd.DataFrame(pd.read_csv(\"data/database/201706.csv\"))\n",
    "    df2017_7 = pd.DataFrame(pd.read_csv(\"data/database/201707.csv\"))\n",
    "    df2017_8 = pd.DataFrame(pd.read_csv(\"data/database/201708.csv\"))\n",
    "    df2017_9 = pd.DataFrame(pd.read_csv(\"data/database/201709.csv\"))\n",
    "    df2017_10 = pd.DataFrame(pd.read_csv(\"data/database/201710.csv\"))\n",
    "    df2017_11 = pd.DataFrame(pd.read_csv(\"data/database/201711.csv\"))\n",
    "    df2017_12 = pd.DataFrame(pd.read_csv(\"data/database/201712.csv\"))\n",
    "\n",
    "    df = [[df2017_1, df2017_2, df2017_3, df2017_4, df2017_5, df2017_6, df2017_7, df2017_8, df2017_9, df2017_10, df2017_11, df2017_12],[df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12]]\n",
    "    \n",
    "    def load_2019_df(rental_no, w , df2019_1, df2019_2, df2019_3):\n",
    "        wt = load_weather_month(w, 1)\n",
    "        datat, baset = calculate_date(df2019_1)\n",
    "        temp = concat_columns(datat, wt, baset, rental_no)\n",
    "\n",
    "        wt1 = load_weather_month(w, 2)\n",
    "        datat1, baset1 = calculate_date(df2019_2)\n",
    "        temp1 = concat_columns(datat1, wt1, baset1, rental_no)\n",
    "\n",
    "        wt3 = load_weather_month(w, 3)\n",
    "        datat2, baset2 = calculate_date(df2019_3)\n",
    "        temp2 = concat_columns(datat2, wt3, baset2, rental_no)\n",
    "    \n",
    "        result = pd.concat([temp, temp1, temp2])\n",
    "        return result\n",
    "        \n",
    "    def load_2019():\n",
    "        df2019_1 = pd.DataFrame(pd.read_csv(\"data/database/201901.csv\"))\n",
    "        df2019_2 = pd.DataFrame(pd.read_csv(\"data/database/201902.csv\"))\n",
    "        df2019_3 = pd.DataFrame(pd.read_csv(\"data/database/201903.csv\"))\n",
    "        weather = pd.read_csv(\"data/database/2019weather.csv\")\n",
    "        dfw1 = pd.DataFrame(weather)\n",
    "        dfw1['일시'] = pd.to_datetime(dfw1['일시'], errors='coerce')\n",
    "        dfw1['월'] = dfw1['일시'].dt.month\n",
    "        dfw1['일'] = dfw1['일시'].dt.day\n",
    "        dfw1['시'] = dfw1['일시'].dt.hour\n",
    "        \n",
    "        t1 = load_2019_df(207, dfw1, df2019_1, df2019_2, df2019_3)\n",
    "        t2 = load_2019_df(502, dfw1, df2019_1, df2019_2, df2019_3)\n",
    "        t3 = load_2019_df(113, dfw1, df2019_1, df2019_2, df2019_3)\n",
    "        t4 = load_2019_df(2102, dfw1, df2019_1, df2019_2, df2019_3)\n",
    "        t5 = load_2019_df(1210, dfw1, df2019_1, df2019_2, df2019_3)\n",
    "        t6 = load_2019_df(152, dfw1, df2019_1, df2019_2, df2019_3)\n",
    "        t7 = load_2019_df(1308, dfw1, df2019_1, df2019_2, df2019_3)\n",
    "        t8 = load_2019_df(2219, dfw1, df2019_1, df2019_2, df2019_3)\n",
    "        t9 = load_2019_df(1906, dfw1, df2019_1, df2019_2, df2019_3)\n",
    "        t10 = load_2019_df(907, dfw1, df2019_1, df2019_2, df2019_3)\n",
    "        t= pd.concat([t1,t2,t3,t4,t5,t6,t7,t8,t9,t10]).reset_index(drop=True)\n",
    "        \n",
    "        return t  \n",
    "    \n",
    "    def load_weather():\n",
    "        weather = pd.read_csv(\"data/database/2017weather.csv\")\n",
    "        dfw1 = pd.DataFrame(weather)\n",
    "        dfw1['일시'] = pd.to_datetime(dfw1['일시'], errors='coerce')\n",
    "        dfw1['월'] = dfw1['일시'].dt.month\n",
    "        dfw1['일'] = dfw1['일시'].dt.day\n",
    "        dfw1['시'] = dfw1['일시'].dt.hour\n",
    "        weather1 = pd.read_csv(\"data/database/2018weather.csv\")\n",
    "        dfw2 = pd.DataFrame(weather1)\n",
    "        dfw2['일시'] = pd.to_datetime(dfw2['일시'], errors='coerce')\n",
    "        dfw2['월'] = dfw2['일시'].dt.month\n",
    "        dfw2['일'] = dfw2['일시'].dt.day\n",
    "        dfw2['시'] = dfw2['일시'].dt.hour\n",
    "        dfw = [dfw1, dfw2]\n",
    "        return dfw\n",
    "\n",
    "    dfw = load_weather()\n",
    "\n",
    "    def load_weather_month(weather, mon):\n",
    "        weather1 = weather[weather['월'] == mon]\n",
    "        weather1 = weather1.drop(['일시','월'], 1).reset_index(drop=True)\n",
    "        return weather1\n",
    "\n",
    "    def calculate_date(df):\n",
    "        dft = df\n",
    "        dft['대여시간'] = pd.to_datetime(dft['대여시간'], errors='coerce')\n",
    "        dft['년'] = dft['대여시간'].dt.year - 2010\n",
    "        dft['요일'] = dft['대여시간'].dt.weekday\n",
    "        dft['월'] = dft['대여시간'].dt.month\n",
    "        dft['일'] = dft['대여시간'].dt.day\n",
    "        dft['시'] = dft['대여시간'].dt.hour\n",
    "        base = pd.DataFrame(dft.drop_duplicates(['일','시'])).reset_index(drop=True)\n",
    "        dftemp = df[df['대여장소'].isin(rental)]\n",
    "        return dftemp, base\n",
    "\n",
    "    def concat_columns(dftemp, dfw, base, rental_no):\n",
    "        temp1 = base\n",
    "        dftemp113 = dftemp[dftemp['대여장소'] == rental_no]\n",
    "        #print(pd.crosstab(dftemp113['일'], dftemp113['시'], margins=False))\n",
    "        fre = pd.crosstab(dftemp113['일'], dftemp113['시'], margins=False).values.flatten()\n",
    "        frelist = fre.tolist()\n",
    "\n",
    "        for i in range(int(dfw.shape[0]/24)):\n",
    "            if((dftemp113[dftemp113['일'] == (i+1)]).shape[0]==0):\n",
    "                for x in range(24):\n",
    "                    frelist.insert((i*24)+x ,0)\n",
    "\n",
    "        for i in range(24):\n",
    "            if((dftemp113[dftemp113['시'] == i]).shape[0]==0):\n",
    "                for x in range(int(dfw.shape[0]/24)):\n",
    "                    frelist.insert((i+(x*24)),0)\n",
    "\n",
    "        fre = np.array(frelist)                        \n",
    "        fre = pd.DataFrame(fre, columns=['건수'])\n",
    "        temp1['대여장소'] = rental_no\n",
    "        temp1['빈도수'] = fre['건수']\n",
    "        temp1 = temp1.drop(['대여시간', '반납시간', '반납장소'], 1)\n",
    "        temp1 = pd.merge(temp1, dfw, on=['일', '시'])\n",
    "        temp1 = temp1.drop(['일'], 1)\n",
    "        return temp1\n",
    "\n",
    "    def data_no(rental_no):\n",
    "        dfwlist = []\n",
    "        data = [0 for _ in range(12)]\n",
    "        base = [0 for _ in range(12)]\n",
    "        temp = [0 for _ in range(12)]\n",
    "        r = pd.DataFrame()\n",
    "        for x in range(len(dfw)):\n",
    "            for i in range(12):\n",
    "                dfwlist.append(load_weather_month(dfw[x], i+1))\n",
    "\n",
    "            for i in range(12):\n",
    "                data[i], base[i] = calculate_date(df[x][i])\n",
    "\n",
    "            for i in range(12):\n",
    "                temp[i] = concat_columns(data[i], dfwlist[12*x+i], base[i], rental_no)\n",
    "\n",
    "            result = pd.concat([temp[0],temp[1],temp[2],temp[3],temp[4],temp[5],temp[6],temp[7],temp[8],temp[9],temp[10],temp[11]]).reset_index(drop=True)\n",
    "            r = pd.concat([r, result])\n",
    "\n",
    "        return r.reset_index(drop=True)\n",
    "    \n",
    "    t2019 = load_2019()\n",
    "    \n",
    "\n",
    "    t1 = data_no(207)\n",
    "    t2 = data_no(502)\n",
    "    t3 = data_no(113)\n",
    "    t4 = data_no(2102)\n",
    "    t5 = data_no(1210)\n",
    "    t6 = data_no(152)\n",
    "    t7 = data_no(1308)\n",
    "    t8 = data_no(2219)\n",
    "    t9 = data_no(1906)\n",
    "    t10 = data_no(907)\n",
    "    t2018 = pd.concat([t1,t2,t3,t4,t5,t6,t7,t8,t9,t10]).reset_index(drop=True)\n",
    "    \n",
    "    t2018 = t2018.join(pd.get_dummies(t2018['요일'], prefix=\"요일\"))\n",
    "    t2019 = t2019.join(pd.get_dummies(t2019['요일'], prefix=\"요일\"))\n",
    "    \n",
    "    t = pd.concat([t2018,t2019]).reset_index(drop=True)    \n",
    "    t.to_pickle('data/pickle/5번테스트.pkl')\n",
    "    \n",
    "t = t[t['대여장소'] == 207].reset_index(drop=True)  \n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 6.103172175364371\n",
      "ridge 6.103150404618546\n",
      "SVR 3.9774890288531375\n",
      "lasso 6.074032977760952\n",
      "elastic 6.081672377771481\n",
      "LassoLars 7.394132681164209\n",
      "LogisticRegression 6.350101626016261\n",
      "SGDRegressor 155594551934.1727\n",
      "Perceptron 10.388211382113822\n",
      "xgboost 3.9773436440230627\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(t[features], t['빈도수'], test_size=0.1, random_state=15)\n",
    "\n",
    "models = [\n",
    "    ('lr', lm.LinearRegression(n_jobs=-1)),\n",
    "    ('ridge', lm.Ridge()),\n",
    "    ('SVR', SVR()),\n",
    "    ('lasso', lm.Lasso()),\n",
    "    ('elastic', lm.ElasticNet()),\n",
    "    ('LassoLars', lm.LassoLars()),\n",
    "    ('LogisticRegression', lm.LogisticRegression()),\n",
    "    ('SGDRegressor', lm.SGDRegressor()),\n",
    "    ('Perceptron', lm.Perceptron(n_jobs=-1)),\n",
    "    ('xgboost', xgb.XGBRegressor(objective= 'reg:squarederror'))\n",
    "]\n",
    "\n",
    "n=3\n",
    "params = { \n",
    "    'lr' :{ \n",
    "    }, \n",
    "    'SVR':{ \n",
    "    },\n",
    "    'ridge': { \n",
    "    }, \n",
    "    'lasso': { \n",
    "    }, \n",
    "    'elastic': { \n",
    "    }, \n",
    "    'LassoLars': {\n",
    "    }, \n",
    "    'LogisticRegression': { \n",
    "    }, \n",
    "    'SGDRegressor':{ \n",
    "    }, \n",
    "    'Perceptron' :{ \n",
    "    }, \n",
    "    'xgboost': { \n",
    "    }\n",
    "}\n",
    "\n",
    "best_model, best_mae = None, float('inf')\n",
    "\n",
    "for model_name, model in models:\n",
    "    param_grid = params[model_name]\n",
    "    grid = GridSearchCV(model, cv=5, n_jobs=-1, param_grid=param_grid)\n",
    "    grid = grid.fit(x_train, y_train)\n",
    "\n",
    "    model = grid.best_estimator_\n",
    "    predictions = model.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    print(model_name, mae)\n",
    "\n",
    "    if mae < best_mae:\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:squarederror',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
